<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Charlie Snell</title>
  
  <meta name="author" content="Charlie Snell">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  <script type="text/javascript" src="script.js"></script>
</head>

<body onload="startGame()">
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Charlie Snell</name>
              </p>
              <p>
                I'm a second year CS PhD student in Berkeley EECS advised by Dan Klein and Sergey Levine. I am also a Student Researcher at Google DeepMind. Previously, I was a UC Berkeley undergrad, where I had the great opportunity to work with and learn from a number of fantastic AI researchers, such as <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>, <a href="https://ruiqi-zhong.github.io">Ruiqi Zhong</a>, <a href="https://people.eecs.berkeley.edu/~klein/">Dan Klein</a>, <a href="https://jsteinhardt.stat.berkeley.edu">Jacob Steinhardt</a>, and <a href="https://www.cs.jhu.edu/~jason/">Jason Eisner</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:csnell22@berkeley.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=dD7EpwQAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/sea_snell/">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/Sea-Snell/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile_full.JPG"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
        <table style="padding-bottom:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <br>
              <br>
              See Google Scholar for more.
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/FalsePromise.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>The False Promise of Imitating Proprietary LLMs</papertitle>
              <br>
              <a href="https://www.perplexity.ai/search/888d8192-f514-44be-a764-a272248e85c9">Arnav Gudibande</a><sup>*</sup>, 
              <a href="https://www.ericswallace.com">Eric Wallace</a><sup>*</sup>, 
              <strong>Charlie Snell</strong><sup>*</sup>, 
              <a href="https://young-geng.xyz">Xinyang Geng</a>, 
              <a href="https://www.haoliu.site">Hao Liu</a>, 
              <a href="https://people.eecs.berkeley.edu/~pabbeel/">Pieter Abbeel</a>, 
              <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>, 
              <a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a>
              <br>
              <em>ICLR 2024</em>
              <br>
							<a href="https://arxiv.org/abs/2305.15717">[paper]</a>
              <p></p>
              <p>Recent systems ‚Äì like <a href="https://bair.berkeley.edu/blog/2023/04/03/koala/">Koala</a>, <a href="https://lmsys.org/blog/2023-03-30-vicuna/">Vicuna</a>, and <a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">Alpaca</a> ‚Äì finetune a weaker language model to imitate the outputs of a stronger model, like ChatGPT or GPT-4. In this work, we critically analyze the shortcomings of this approach.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/context_distill.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Learning by Distilling Context</papertitle>
              <br>
              <strong>Charlie Snell</strong>, 
              <a href="https://people.eecs.berkeley.edu/~klein/">Dan Klein</a>,
              <a href="https://ruiqi-zhong.github.io">Ruiqi Zhong</a>
              <br>
              <em>arXiv 2022</em>
              <br>
							<a href="https://arxiv.org/abs/2209.15189">[paper]</a>
              <a href="https://t.co/O4a6XJUBKu">[talk]</a>
              <p></p>
              <p>Language models significantly benefit from context tokens, such as prompts or scratchpads. We propose to apply context distillation so that a language model can improve itself by internalizing these gains.</p>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/ILQL_site_img.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Offline RL for Natural Language Generation with Implicit Language Q Learning</papertitle>
              <br>
              <strong>Charlie Snell</strong>, 
              <a href="https://www.kostrikov.xyz">Ilya Kostrikov</a>,
              <a href="https://www.yisu.moe/">Yi Su</a>, 
              <a href="https://sherryy.github.io/">Mengjiao Yang</a>, 
              <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>
              <br>
              <em>ICLR 2023</em>
              <br>
							<a href="https://arxiv.org/abs/2206.11871">[paper]</a>
              <a href="https://sea-snell.github.io/ILQL_site/">[project page]</a>
							<a href="https://github.com/Sea-Snell/Implicit-Language-Q-Learning/">[code]</a>
              <a href="https://youtu.be/fGq4np3brbs">[talk]</a>
              <p></p>
              <p>We propose an effective and easy-to-use offline RL motivated method for steering language models towards successfully completing language tasks, such as goal directed dialogue, controled generation, and word games.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/APEL_main.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Non-Programmers Can Label Programs Indirectly via Active Examples: A Case Study with Text-to-SQL</papertitle>
              <br>
              <a href="https://ruiqi-zhong.github.io">Ruiqi Zhong</a><sup>*</sup>, 
              <strong>Charlie Snell</strong><sup>*</sup>, 
              <a href="https://people.eecs.berkeley.edu/~klein/">Dan Klein</a>, 
              <a href="https://www.cs.jhu.edu/~jason/">Jason Eisner</a>
              <br>
              <em>EMNLP 2023</em>
              <br>
							<a href="https://arxiv.org/abs/2205.12422/">[paper]</a>
              <p></p>
              <p>We introduce APEL, a new framework that enables non-programmers to indirectly annotate natural language utterances with executable meaning representations, such as SQL programs.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/SummarizingDifferencesMain.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Describing Differences between Text Distributions with Natural Language</papertitle>
              <br>
              <a href="https://ruiqi-zhong.github.io">Ruiqi Zhong</a>, 
              <strong>Charlie Snell</strong>, 
              <a href="https://people.eecs.berkeley.edu/~klein/">Dan Klein</a>, 
              <a href="https://jsteinhardt.stat.berkeley.edu/">Jacob Steinhardt</a>
              <br>
              <em>ICML 2022</em>
              <br>
							<a href="https://arxiv.org/abs/2201.12323/">[paper]</a>
							<a href="https://github.com/ruiqi-zhong/DescribeDistributionalDifferences/">[code]</a>
              <p></p>
              <p>How do two distributions of text differ? We propose a method for automatically summarizing the differences by "learning a natural language hypothesis".</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/MiniADFigure.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Context-Aware Language Modeling for Goal-Oriented Dialogue Systems</papertitle>
              <br>
              <strong>Charlie Snell</strong>, 
              <a href="https://sherryy.github.io/">Mengjiao Yang</a>, 
              <a href="https://github.com/justinjfu/">Justin Fu</a>, 
              <a href="https://www.yisu.moe/">Yi Su</a>, 
              <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>
              <br>
              <em>NAACL 2022, Findings</em>
              <br>
							<a href="https://arxiv.org/abs/2204.10198/">[paper]</a>
              <a href="https://sea-snell.github.io/CALM_LM_site/">[project page]</a>
							<a href="https://github.com/Sea-Snell/CALM-Dialogue/">[code]</a>
              <p></p>
              <p>We extend techniques from learning-based control, such as task relabeling, to derive a simple and effective method to finetune language models in a goal-aware way.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/AttentionMain.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Approximating How Single Head Attention Learns</papertitle>
              <br>
              <strong>Charlie Snell<sup>*</sup></strong>, 
              <a href="https://ruiqi-zhong.github.io">Ruiqi Zhong</a><sup>*</sup>, 
              <a href="https://people.eecs.berkeley.edu/~klein/">Dan Klein</a>, 
              <a href="https://jsteinhardt.stat.berkeley.edu/">Jacob Steinhardt</a>
              <br>
              <em>arXiv 2021</em>
              <br>
							<a href="https://arxiv.org/abs/2103.07601/">[paper]</a>
              <a href="https://github.com/ruiqi-zhong/presentations/blob/main/attentiontraining.pdf/">[slides]</a>
							<a href="https://github.com/Sea-Snell/AttentionDynamics/">[code]</a>
              <a href="https://sea-snell.github.io/AttentionBlogSite/attention/2021/04/01/attention.html">[blog]</a>
              <p></p>
              <p>Why do models often attend to salient words, and how does this evolve throughout training?</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/BPL.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>The Omniglot Jr. challenge; Can a model achieve child-level character generation and classification?</papertitle>
              <br>
              Eliza Kosoy, 
              Masha Belyi, 
              <strong>Charlie Snell</strong>, 
              <a href="https://web.mit.edu/cocosci/josh.html">Josh Tenenbaum</a>, 
              <a href="https://cims.nyu.edu/~brenden/">Brenden Lake</a>, 
              <a href="http://alisongopnik.com">Alison Gopnik</a>
              <br>
              <em>NeurIPS Workshop on BabyMind 2020</em>
              <br>
							<a href="https://bi.snu.ac.kr/NeurIPS2020_Babymind/13.pdf">[paper]</a>
              <p></p>
              <p>We augment the original Omniglot dataset with a new dataset of children's handwritten characters. We then study the properties of a Bayesian Program Learning model trained on this new data.</p>
            </td>
          </tr>

        </table>
      
      <table style="padding-top:20px;padding-bottom: 20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Assorted Writing</heading>
            <br>
            <br>
            I've had the pleasure of getting to write several articles for <a href="https://ml.berkeley.edu/">Machine Learning at Berkeley's</a> <a href="https://ml.berkeley.edu/blog/">technical blog</a>.
          </td>
        </tr>
      </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/AlienDreamsBlog.png' width="160">
            </div>
          </td>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <blogtitle>Alien Dreams: An Emerging Art Scene</blogtitle>
            <br>
            June 2021
            <br>
            <a href="https://ml.berkeley.edu/blog/posts/clip-art/">[blog]</a>
            <a href="https://www.vice.com/en/article/n7bqj7/ai-generated-art-scene-explodes-as-hackers-create-groundbreaking-new-tools/">[co</a><a href="https://read.deeplearning.ai/the-batch/issue-100/">ver</a><a href="https://jack-clark.net/2021/07/06/import-ai-256-facial-recognition-vs-covid-masks-what-ai-means-for-warfare-clip-and-ai-art/">age]</a>
            <a href="https://news.ycombinator.com/item?id=27696369">[disc</a><a href="https://twitter.com/sea_snell/status/1410360593350115330?s=20&t=T1-cDUchP8qfeuGiA_tvYQ">ussion]</a>
            <p></p>
            <p>A tour through the wonderful AI art scene that emerged when CLIP was released in January 2021.</p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/DALLE_blog_pt2.jpg' width="160">
            </div>
          </td>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <blogtitle>How is it so good ? (DALL-E Explained Pt. 2)</blogtitle>
            <br>
            April 2021
            <br>
            <a href="https://ml.berkeley.edu/blog/posts/dalle2/">[blog]</a>
            <p></p>
            <p>A technical and philosophical discussion of how DALL-E works, why it is so effective at generating images from a text prompt, and its theoretical limitations.</p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/VQVAE_blog.png' width="160">
            </div>
          </td>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <blogtitle>Understanding VQ-VAE (DALL-E Explained Pt. 1)</blogtitle>
            <br>
            February 2021
            <br>
            <a href="https://ml.berkeley.edu/blog/posts/vq-vae/">[blog]</a>
            <p></p>
            <p>How do vector quantized variational autoencoders (VQ-VAEs) work? And what role do they play in modern generative models, such as DALL-E and Jukebox?</p>
          </td>
        </tr>
      </tbody></table>

      <table style="padding-top:20px;padding-bottom: 20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Side Projects / Open Source Implementations</heading>
          <br>
          <br>
          Selected projects. See my <a href="https://github.com/Sea-Snell/">github</a> for much more.
          <br>
          <br>
          <em>(Press "y" to add a random circle, "n" to remove one, and "wasd" to pan.)</em>
        </td>
      </tr>
    </tbody></table>
    
    <div id="projects"></div>
    
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;" id="projects_body"><tbody>
      <tr>
        <td style="padding:80px;width:100%;vertical-align:middle">
          <projecttitle>JaxSeq</projecttitle>
          <br>
          October 2022
          <br>
          <a href="https://github.com/Sea-Snell/JAXSeq">[code]</a>
          <p></p>
          <p>Built on top of HuggingFace's Transformers library, JaxSeq enables training very large language models in Jax with model and data parallelism across both multi-device and multi-node clusters.</p>
        </td>
        <td style="padding:80px;width:25%;vertical-align:middle">
          <img src='images/JaxSeq.png' width="320">
        </td>
      </tr>
      
      <tr>
        <td style="padding:80px;width:25%;vertical-align:middle">
          <img src='images/grokk.png' width="320">
        </td>
        <td style="padding:80px;width:100%;vertical-align:middle">
          <projecttitle>Re-implementation of the paper "Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets"</projecttitle>
          <br>
          November 2021
          <br>
          <a href="https://github.com/Sea-Snell/grokking/">[code]</a>
          <p></p>
          <p>Re-create the dramatic train/test curves from the original paper; experiment with the grokking phenomenon yourself.</p>
        </td>
      </tr>

      <tr>
        <td style="padding:80px;width:100%;vertical-align:middle">
          <projecttitle>Music Preference Visualization with Deep Embeddings</projecttitle>
          <br>
          June-July 2020
          <br>
          <a href="https://twitter.com/sea_snell/status/1382479182525976581?s=20&t=xttJXbokhqIff9jA8XjaLg/">[tweet]</a>
          <p></p>
          <p>Harness the power of deep music representations to generate playlists and visualize your music preferences in an interactive web app.</p>
        </td>
        <td style="padding:80px;width:25%;vertical-align:middle">
          <img src='images/music.jpeg' width="320">
        </td>
      </tr>

      <tr>
        <td style="padding:80px;width:25%;vertical-align:middle">
          <img src='images/charseq.jpeg' width="320">
        </td>
        <td style="padding:80px;width:100%;vertical-align:middle">
          <projecttitle>Train Deep Neural Networks on a 2013 Macbook Air GPU</projecttitle>
          <br>
          2017/2018
          <br>
          <a href="https://github.com/Sea-Snell/MLLibCpp">[code]</a>
          <p></p>
          <p>A deep learning framework implemented from scratch in C++/OpenCL. Implements GPU kernels that can run on a 2013 Macbook Air GPU (and other Apple computers). Implements LSTM training/inference for music lyric generation.</p>
        </td>
      </tr>

      <tr>
        <td style="padding:80px;width:100%;vertical-align:middle">
          <projecttitle>Yeah JeCUB App</projecttitle>
          <br>
          2017/2018
          <br>
          <a href="https://apps.apple.com/us/app/yeah-jecub/id1223249592">[app store]</a>
          <p></p>
          <p>A humorous sound-box app.</p>
        </td>
        <td style="padding:80px;width:25%;vertical-align:middle">
          <img src='images/jecub.jpeg' width="320">
        </td>
      </tr>

      <tr>
        <td style="padding:80px;width:25%;vertical-align:middle">
          <img src='images/block_world.png' width="320">
        </td>
        <td style="padding:80px;width:100%;vertical-align:middle">
          <projecttitle>2D Procedural Endless World</projecttitle>
          <br>
          2015
          <br>
          <a href="https://github.com/Sea-Snell/2d-procedural-endless-world">[code]</a>
          <p></p>
          <p>Scroll through an infinite 2D block-world consisting of rugged terrain, endless caves, fluffy clouds, and extreme biomes all synthesized by PRNGs and Perlin Noise.</p>
        </td>
      </tr>

    </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:0px">
          <br>
          <p style="text-align:right;font-size:small;">
            Website design from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>
          </p>
        </td>
      </tr>
    </tbody></table>
</body>

</html>
